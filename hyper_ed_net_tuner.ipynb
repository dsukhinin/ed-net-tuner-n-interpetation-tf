{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e9952c-f53b-4ec3-a8c3-bbaa3652724d",
   "metadata": {},
   "source": [
    "# Tuning Envelope Detector net and best model weights interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea8b90-55df-4c49-938d-2f9b7627e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Use this or tf random seed for train ds in singe expriment\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f8aae-bdf9-45c9-8cd4-0cee7f938cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#Loading config file\n",
    "with open('config.json') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e20ea-9688-4ee4-b467-0dbeb259ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHANNELS = config[\"n_channels\"]\n",
    "\n",
    "N_CLASSES = config[\"n_classes\"]\n",
    "\n",
    "\n",
    "ECOG_INT_LEN = config[\"n_points\"]\n",
    "\n",
    "\n",
    "DATA_DIR = config[\"data_dir\"]\n",
    "\n",
    "\n",
    "X = np.load(os.path.join(DATA_DIR, config[\"x_file\"]), allow_pickle=True)\n",
    "\n",
    "Y = np.load(os.path.join(DATA_DIR,  config[\"y_file\"]), allow_pickle=True)\n",
    "\n",
    "\n",
    "#number of examples\n",
    "split = config[\"val_split\"]\n",
    "\n",
    "y_tr = np.arange(0, Y.shape[0])\n",
    "\n",
    "x_tr = y_tr[:int(Y.shape[0]*split)]\n",
    "\n",
    "y_val = y_tr[int(Y.shape[0]*split):]\n",
    "\n",
    "\n",
    "\n",
    "def read_one(idx, training=True):\n",
    "    \n",
    "    y_f = Y[idx]\n",
    "    \n",
    "    x_f = X[idx]\n",
    "    # in case of data augmentation\n",
    "    if training:\n",
    "        # ...\n",
    "        pass  \n",
    "          \n",
    "    return x_f.astype(\"float32\"),y_f.astype(\"int32\")\n",
    "    \n",
    "def preprocess(idx):\n",
    "    \n",
    "    spec, audio = tf.numpy_function(read_one, [idx, False], [tf.float32, tf.int32])\n",
    "    \n",
    "    return spec, audio\n",
    "\n",
    "\n",
    "def preprocess_val(idx):\n",
    "    \n",
    "    spec, audio = tf.numpy_function(read_one, [idx, False], [tf.float32, tf.int32])\n",
    "    \n",
    "    return spec, audio\n",
    "\n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_tr,))\n",
    "train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((y_val,))\n",
    "test_dataset = test_dataset.map(preprocess_val, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243ea0d-6849-48dd-9fbf-d2afa5232e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow import keras\n",
    "import keras_tuner\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "LR_RATE = config[\"learning_rate\"]\n",
    "weight_decay = config[\"weight_decay\"]\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=LR_RATE, weight_decay=weight_decay)\n",
    "\n",
    "lfn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "msca = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "\n",
    "#envelope detector net\n",
    "def ed_net(input_shape, n_branches, lstm_units, filtering_size = 25, envelope_size = 15):\n",
    "    DOWNSAMPLING =  10\n",
    "    FILTERING_SIZE = filtering_size\n",
    "    ENVELOPE_SIZE = envelope_size\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv1D(n_branches, 1, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization(center=False, scale=False)(x)\n",
    "    \n",
    "    x = layers.Conv1D(n_branches, FILTERING_SIZE, padding=\"same\", groups=n_branches, use_bias = False)(x)\n",
    "    x = layers.BatchNormalization(center=False, scale=False)(x)\n",
    "    x = layers.LeakyReLU(-1)(x)\n",
    "    \n",
    "    x = layers.Conv1D(n_branches, ENVELOPE_SIZE, padding=\"same\",  groups=n_branches, use_bias = False)(x)\n",
    "    \n",
    "    x = x[:,::DOWNSAMPLING,:]\n",
    "    \n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units//2))(x)\n",
    "    \n",
    "    x = layers.BatchNormalization(center=False, scale=False)(x)\n",
    "    \n",
    "    outputs = layers.Dense(N_CLASSES, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name=f'ed_net_b_{n_branches}_l_{lstm_units}_f_{filtering_size}_e_{envelope_size}')\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss= lfn, metrics=msca)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    # defauls optimals\n",
    "    \n",
    "    n_branches = 64 \n",
    "    lstm_units = 32\n",
    "    \n",
    "    f_size = 25\n",
    "    e_size = 15\n",
    "    \n",
    "    if config[\"tune_n_branches\"] :\n",
    "    \n",
    "        n_branches = hp.Int(\"n_branches\", min_value=config[\"branches_min\"], max_value=config[\"branches_max\"], step=config[\"branches_step\"])\n",
    "        \n",
    "    if config[\"tune_n_lstm\"] :\n",
    "    \n",
    "        lstm_units = hp.Int(\"lstm_units\", min_value=config[\"lstm_units_min\"], max_value=config[\"lstm_units_max\"], step=config[\"lstm_units_step\"])\n",
    " \n",
    "\n",
    "    if config[\"tune_filtering_size\"] :\n",
    "        \n",
    "        f_size = hp.Int(\"f_size\", min_value=config[\"filtering_min\"], max_value=config[\"filtering_max\"], step=config[\"filtering_max\"])\n",
    "        \n",
    "\n",
    "    if config[\"tune_envelope_size\"] :\n",
    "    \n",
    "        e_size = hp.Int(\"e_size\", min_value=config[\"envelope_min\"], max_value=config[\"envelope_max\"], step=config[\"envelope_step\"])\n",
    "    \n",
    "    \n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = ed_net((ECOG_INT_LEN, N_CHANNELS), n_branches = n_branches, lstm_units = lstm_units, filtering_size = f_size, envelope_size = e_size)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb7ec8-e999-453f-a1bc-c0b16b653de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training & tuning\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\", # modify here for you project and in config.json\n",
    "    max_trials=config[\"n_trials\"],\n",
    "    executions_per_trial=config[\"n_runs_per_trial\"],\n",
    "    overwrite=True,\n",
    "    directory=config[\"tuner_directory\"],\n",
    "    project_name=config[\"project_name\"],\n",
    ")\n",
    "\n",
    "BATCH_SIZE = config[\"batch_size\"]\n",
    "N_EPOCH = config[\"n_epoch\"]\n",
    "\n",
    "tuner.search(train_dataset.shuffle(200).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE), \n",
    "              validation_data =test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE),\n",
    "            epochs=N_EPOCH\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafacc1e-bf84-46e6-8cd2-adfc702f2c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72799c-daf6-4947-b30f-0b157dc9fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "\n",
    "best_model = models[0]\n",
    "# Build the best model.\n",
    "\n",
    "best_model.build(input_shape=(ECOG_INT_LEN, N_CHANNELS))\n",
    "best_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190fe75-cc3c-4e77-8655-b63d78000d7a",
   "metadata": {},
   "source": [
    "# Model weights interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217efec-3ece-4548-b1bf-197edae9e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data\n",
    "\n",
    "model =  keras.Model(best_model.inputs, [best_model.outputs, best_model.layers[2]],\n",
    "\n",
    "X_unmixed = []\n",
    "\n",
    "feature_grads = []\n",
    "\n",
    "for b_id, (x_val, y_val) in enumerate(train_dataset):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        val_logits, unmix = model(x_val, training=False)\n",
    "        \n",
    "    grad = tape.gradient(val_logits, model.layers[6].variables)\n",
    "    \n",
    "    feature_grads.append(grad[0].numpy())\n",
    "    \n",
    "    X_unmixed.append(unmix.numpy())\n",
    "    \n",
    "X_unmixed = np.concatenate(X_unmixed, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b197c-7ccf-4d82-893d-ef88eb8a641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpreting ... \n",
    "import sklearn\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spat_l =  model.layers[1].weights[0]\n",
    "\n",
    "temp_l =  model.layers[3].weights[0]\n",
    "\n",
    "\n",
    "NPERSEQ = 500\n",
    "\n",
    "HIDDEN_CHANNELS = 32 # \n",
    "\n",
    "N_TOP_BRANCHES = 5\n",
    "\n",
    "FREQUENCY = 1000\n",
    "\n",
    "COMPARISON_TOLERANCE = 10\n",
    "\n",
    "ZOOM = 125\n",
    "\n",
    "\n",
    "def get_spatial_patterns(X, temporal_weights, spatial_weights):\n",
    "    \n",
    "    \n",
    "    patterns = np.zeros((spatial_weights.shape[1], spatial_weights.shape[0]))\n",
    "    \n",
    "    for i in range(temporal_weights.shape[2]): # == n_hidden ch \n",
    "        \n",
    "        X_filtered = np.zeros(X.shape)\n",
    "        \n",
    "        for j in range(X_filtered.shape[1]):\n",
    "            \n",
    "            X_filtered[:, j] = np.convolve(X[:, j], temporal_weights[:, 0, i], mode=\"same\")\n",
    "            \n",
    "        patterns[i, :] = np.dot(np.cov(X_filtered, rowvar=False), spatial_weights[:, i].reshape((-1, 1)))[:, 0]\n",
    "        \n",
    "    return patterns\n",
    "\n",
    "def get_freq_domain(signal, frequency):\n",
    "    n = NPERSEQ\n",
    "    amplitude = np.abs(np.fft.fft(signal,n))\n",
    "    frequencies = np.fft.fftfreq(n , 1 / frequency)\n",
    "    assert len(amplitude) == len(frequencies), f\"{len(amplitude)}!={len(frequencies)}\"\n",
    "    end = int(len(frequencies)/2)\n",
    "    return frequencies[:end], amplitude[:end]\n",
    "\n",
    "\n",
    "\n",
    "convs_weights = temp_l\n",
    "\n",
    "interpret_patterns = get_spatial_patterns(\n",
    "    np.copy(X_test[10000:510000, :]),\n",
    "    convs_weights,\n",
    "    np.repeat(np.copy(spat_l[0]), 1, axis=1),\n",
    "    ).reshape(X_train.shape[1], HIDDEN_CHANNELS, 1)\n",
    "\n",
    "\n",
    "\n",
    "assert interpret_patterns.shape[2] == 1 #\n",
    "\n",
    "\n",
    "importance_weights = np.sum(np.sum(np.abs(feature_grads).squeeze(), axis=0), axis=0)\n",
    "importance_weights = importance_weights / sum(importance_weights)\n",
    "\n",
    "importance_indexes = np.argsort(-importance_weights)\n",
    "\n",
    "\n",
    "assert len(importance_indexes) == interpret_patterns.shape[1]\n",
    "\n",
    "X_unmixed = X_unmixed.reshape(-1, HIDDEN_CHANNELS)\n",
    "\n",
    "for i in importance_indexes[:N_TOP_BRANCHES]:\n",
    "\n",
    "    FINAL_FUGURE, FINAL_AXIS = plt.subplots(1, 2, gridspec_kw={'width_ratios': [1, 2],'height_ratios': [1]})\n",
    "    \n",
    "    FINAL_FUGURE.set_figwidth(15)\n",
    "    FINAL_FUGURE.set_figheight(3)\n",
    "    \n",
    "    plt.rc('font', family='serif', size=14)\n",
    "    plt.rc('ytick', labelsize=14)\n",
    "    \n",
    "    plt.setp(FINAL_AXIS[0], title=f'Branch {i}, ({str(round(importance_weights[i], 2))})')\n",
    "\n",
    "    plt.setp(FINAL_AXIS[1], xlabel='Frequency, Hz')\n",
    "\n",
    "    FINAL_AXIS[1].set_title(\"Frequency domain profiles\")\n",
    "\n",
    "    weights = convs_weights[:, 0, i].numpy().T\n",
    "\n",
    "    frequencies_input, spectrum_input = scipy.signal.welch(X_unmixed[:, i], FREQUENCY, nperseg=NPERSEQ, detrend='linear')\n",
    "    frequencies_input = frequencies_input[:-1]\n",
    "    spectrum_input = spectrum_input[:-1]\n",
    "\n",
    "    frequencies, amplitude = get_freq_domain(weights, FREQUENCY)\n",
    "\n",
    "    assert len(frequencies_input) == len(frequencies), f\"{len(frequencies_input)}!={len(frequencies)}\"\n",
    "    assert(\n",
    "        list(np.round(frequencies_input, COMPARISON_TOLERANCE)) ==\\\n",
    "        list(np.round(frequencies, COMPARISON_TOLERANCE))\n",
    "    )\n",
    "\n",
    "    recovered = np.power(sklearn.preprocessing.minmax_scale(amplitude), 1) * sklearn.preprocessing.minmax_scale(spectrum_input)\n",
    "    out_spectrum = np.power(sklearn.preprocessing.minmax_scale(amplitude), 2) * sklearn.preprocessing.minmax_scale(spectrum_input)\n",
    "\n",
    "    frequencies, amplitude = get_freq_domain(weights, FREQUENCY)\n",
    "\n",
    "    figure = FINAL_AXIS[1]\n",
    "\n",
    "    figure.plot(frequencies_input[:ZOOM], sklearn.preprocessing.minmax_scale(spectrum_input)[:ZOOM] * 5, label='Input')\n",
    "    figure.plot(frequencies[:ZOOM], sklearn.preprocessing.minmax_scale(recovered)[:ZOOM], label='Patterns')\n",
    "    figure.plot(frequencies[:ZOOM], sklearn.preprocessing.minmax_scale(amplitude)[:ZOOM], label = 'Weights')\n",
    "    figure.plot(frequencies[:ZOOM], sklearn.preprocessing.minmax_scale(out_spectrum)[:ZOOM], label='Out')\n",
    "    figure.grid()\n",
    "    figure.axis(ymin=0, ymax=1)\n",
    "    figure.legend(bbox_to_anchor=(1, -0.35), ncol=4)\n",
    "\n",
    "    figure = FINAL_AXIS[0]\n",
    "\n",
    "    spatial_new_plot_patterns = np.abs(interpret_patterns[:, i, 0]).transpose()\n",
    "    figure.bar(np.arange(1, ECOG_N_CH+1), spatial_new_plot_patterns / np.sum(spatial_new_plot_patterns))\n",
    "    plt.setp(figure, xlabel='Channel')\n",
    "    plt.setp(figure, ylabel='Importance')\n",
    "\n",
    "\n",
    "FINAL_FUGURE.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
